#!/usr/bin/env python3
"""
Miniflux RSS åŠ æ˜Ÿæ–‡ç« åŒæ­¥è„šæœ¬
å°† Miniflux ä¸­æ”¶è—çš„æ–‡ç« åŒæ­¥ä¸ºæœ¬åœ° Markdown æ–‡ä»¶ï¼Œå¹¶é€šè¿‡ rclone åŒæ­¥åˆ°äº‘ç«¯
"""

import argparse
import logging
import sys
from pathlib import Path

from lib.config import load_config, setup_logging
from lib.ai import analyze_with_claude
from lib.markdown import clean_html, sanitize, generate_markdown
from lib.cloud import sync_to_cloud
from lib.miniflux import MinifluxClient


def process_entry(config, entry):
    """å¤„ç†å•ç¯‡æ–‡ç« ï¼Œè¿”å› (æ–‡ä»¶å, markdownå†…å®¹) æˆ– None"""
    title = entry.get('title', 'Untitled')
    raw_content = entry.get('content', '')
    feed_title = entry.get('feed', {}).get('title', '')

    # HTML è½¬ Markdown
    clean_content = clean_html(raw_content)

    # AI åˆ†æ
    ai_result = analyze_with_claude(config, title, clean_content, feed_title)

    # ç”Ÿæˆ Markdown
    md = generate_markdown(entry, ai_result, clean_content)

    # æ–‡ä»¶åï¼šä¼˜å…ˆä½¿ç”¨ AI ç”Ÿæˆçš„æ™ºèƒ½æ ‡é¢˜
    if ai_result and ai_result.get('smart_title'):
        file_title = ai_result['smart_title']
    else:
        file_title = title

    filename = f"ğŸ“¥ {sanitize(file_title)}"
    return filename, md


def sync(config):
    """ä¸»åŒæ­¥é€»è¾‘"""
    miniflux_config = config['miniflux']
    sync_config = config.get('sync', {})

    temp_path = sync_config.get('temp_path', '/tmp/rss_sync')
    unstar = sync_config.get('unstar_after_sync', True)

    save_dir = Path(temp_path)
    save_dir.mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ– Miniflux å®¢æˆ·ç«¯
    client = MinifluxClient(
        host=miniflux_config['host'],
        api_key=miniflux_config['api_key']
    )

    # è·å–åŠ æ˜Ÿæ–‡ç« 
    limit = sync_config.get('limit', 50)
    entries = client.get_starred_entries(limit)

    if entries is None:
        return 1

    if not entries:
        logging.info("æ²¡æœ‰åŠ æ˜Ÿæ–‡ç« éœ€è¦åŒæ­¥")
        sync_to_cloud(config, temp_path)
        return 0

    # å¤„ç†æ¯ç¯‡æ–‡ç« 
    success_count = 0
    fail_count = 0
    synced_entries = []
    used_filenames = set()

    for entry in entries:
        try:
            result = process_entry(config, entry)
            if not result:
                fail_count += 1
                continue

            filename, md = result

            # å¤„ç†æ–‡ä»¶åå†²çª
            base_filename = filename
            counter = 1
            while filename in used_filenames:
                filename = f"{base_filename}_{counter}"
                counter += 1
            used_filenames.add(filename)

            # ä¿å­˜æ–‡ä»¶
            filepath = save_dir / f"{filename}.md"
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(md)

            logging.info(f"âœ… å·²ä¿å­˜: {filename}")
            success_count += 1
            synced_entries.append(entry)

        except Exception as e:
            title = entry.get('title', 'Unknown')[:50]
            logging.error(f"âŒ ä¿å­˜å¤±è´¥: {title} - {e}")
            fail_count += 1

    logging.info(f"æœ¬åœ°ä¿å­˜å®Œæˆ: æˆåŠŸ {success_count} ç¯‡, å¤±è´¥ {fail_count} ç¯‡")

    # äº‘ç«¯åŒæ­¥
    cloud_ok = sync_to_cloud(config, temp_path)

    # å–æ¶ˆæ”¶è—ï¼ˆä»…äº‘ç«¯åŒæ­¥æˆåŠŸåï¼‰
    if cloud_ok and unstar and synced_entries:
        client.unstar_entries(synced_entries)
    elif not cloud_ok and synced_entries:
        logging.warning("âš ï¸ äº‘ç«¯åŒæ­¥å¤±è´¥ï¼Œä¿ç•™æ”¶è—çŠ¶æ€ï¼Œä¸‹æ¬¡ç»§ç»­å°è¯•")

    return 0 if fail_count == 0 else 1


def main():
    """å…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Miniflux RSS åŠ æ˜Ÿæ–‡ç« åŒæ­¥å·¥å…·')
    parser.add_argument('-c', '--config', help='é…ç½®æ–‡ä»¶è·¯å¾„', default=None)
    args = parser.parse_args()

    config = load_config(args.config)
    setup_logging(config)

    logging.info("=" * 40)
    logging.info("Miniflux RSS åŒæ­¥å¼€å§‹")

    exit_code = sync(config)

    logging.info("Miniflux RSS åŒæ­¥ç»“æŸ")
    logging.info("=" * 40)

    sys.exit(exit_code)


if __name__ == "__main__":
    main()
